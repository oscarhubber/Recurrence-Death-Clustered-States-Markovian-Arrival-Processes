PROGRAMAS_CSMAPS:
V1: Lo que hice en Semana Santa, que incluye versiones preliminares de la lectura de los datasets, las funciones empíricas, las funciones teóricas, y la simulación del CS-MAP
V2: Lo que hice desde final de Semana Santa hasta el 04/05/25, que incluyó una reformulación de las funciones empíricas y debuggeo de la de simulación. También debuggeé algunas teóricas e implementé los casos de condicionamiento por igualdad.
V3: Lo que hice desde el 04/05/25 hasta el 15/05/2025. Implementé la función de log-verosimilitud, pero poco más...
V4: Lo que hice el 16/05/25. Implementé la función que hace cambios de (alpha0, D0, D1) a (alpha0, lambda, P0, P1) y viceversa; y sobre todo implementé el experimento que me pidieron, sobre recoger estadísticas de E(r).
V5: Lo que hice desde el 17/05/25 hasta el 19/05/25. Muy pocos cambios, solo estuve ejecutando la simulación un par de veces con sugerencias de las tutoras. No recuerdo mucho si implementé cambios importantes, e hice esta copia por seguridad.
V6: Lo que hice desde el 20/05/25 hasta el 27/05/25. Estuve varios días ejecutando una nueva versión del experimento, y por fin obtuve los histogramas, con las sugerencias. ¡Esta versión ya no se toca!
V7: Lo que hice desde el 28/05/25 hasta el 02/05/25, después de la Datathon. Tan solo implementé el segundo experimento que me pidió Pepa, y lo dejé ejecutando (40 horas).
V8: Lo que hice el 08/06/25. Comprobé que la función de log-verosimilitud que implementé ya abarcaba el caso de datasets con censura; e implementé las dos primeras funciones objetivo en Python.
V9: Lo que hice desde el 09/06/25 hasta el 23/06/25. Implementé unas dos funciones empíricas más y sus respectivos histogramas que me pidió Pepa, relativos al segundo experimento, pero no hice mucho más porque estuve redactando la memoria.
V10-V11: Algo que hice en agosto. Simplemente hice copias de V9 para volver a ejecutar los experimentos de E(r) y T_D con el objetivo de buscar parámetros de altas correlaciones.

INFERENCIA_CSMAPS:
V1: Del día 30/06/25 (me iba a la segunda convocatoria). Migré tan solo el código necesario para estudiar la inferencia que me pidieron.
V2: Del día 05/07/25. Corregí algunos errores y trabajé con las funciones del optimizador. Descubrí peculiaridades del algoritmo, pero no encontré errores.
V3: Del día 06/07/25. [Nota del 09/07/25: FRACASO, TODO LO SIGUIENTE RESULTÓ SER FALSO]. Primera versión funcional del optimizador. Por fin encontré todos los errores en el optimizador. Lo último que me quedaba era permitir entradas iguales a 0 en las matrices (sin que me diese toda una línea 0).
V4: Del día 08/07/25. Ahora sí que tenemos la primera versión operativa del optimizador. La razón por la que daba error es porque acotar las entradas de alpha0 entre 0 y 1 y definir la última coordenada mediante la fórmula NO ES SUFICIENTE para garantizar que la suma de las coordenadas es 1. Por tanto, se cambió el solver a "trust-constr", y fue necesario incorporar una instancia de la clase "LinearConstraint".
V5: De los días 09/07/25 y 10/07/25. Estuve tuneando más el optimizador base, ya que no funcionaba con la muestra de orden 4 del TFM de Álvaro. Tras unos cambios, descubrí que imponer las condiciones redundantes alpha_i <= 1 hacía el algoritmo mucho más consistente (menos inicializaciones), pero más impreciso (peores tiempos aproximados). Distinguí entre tolerancias en la cota inferior numérica y en la función de log-verosimilitud, y descubrí que la de log-verosimilitud debe ser más estricta (i.e. un número mayor) en la muestra de orden 4. Las correlaciones no pueden ser aproximadas: las estimadas son 0, y las empíricas y teóricas son completamente distintas.
V6: De los días 10/07/25 hasta el 25/07/25. Bajo mantenimiento porque me puse con la memoria. Establecí pruebas en celdas distintas. Se me ocurrió la idea de implementar clases de Python en el futuro (un "objeto" con inicialización la optimización, y método exponer los resultados).
V7: De los días 28/07/25 y 29/07/25. Acabé incorporando el procedimiento de optimización en una clase de Python, ¡como prometí! Más importante aún, empecé a cambiar las funciones empíricas por primera vez en mucho tiempo: estoy intentando hacer que incorporen censura. El caso de la de los momentos de los tiempos parece resuelta, pero las demás todavía no.
V8: De los días 30/07/25 hasta el 03/08/25. Terminé de incorporar la censura en todas las funciones empíricas involucradas en el proceso de optimización. Fue una tarea muy difícil. También incorporé el censurador de Álvaro. También borré unas pocas celdas de pruebas antiguas (cambio pequeño).
V9: Del día 07/08/25. Una simple copia de seguridad.

PRUEBAS_FINALES:
V1: De la primera semana de agosto. Filtré absolutamente todo el código necesario para realizar los experimentos, y preparé las celdas. Varío entre las dimensiones de los parámetros y el valor del cost_coefficient (el peso asociado al término de castigo de las correlaciones). Los primeros resultados para las muestras simuladas han sido exitosos. Después, con las nuevas funciones preparadas para la censura, finalicé experimentos más rigurosos para los datasets reales, y obtuve unos resultados muy buenos. Estoy contento con esto.
V2: Del 09/08/25. No recuerdo los cambios, pero recuerdo que intenté ajustar el código a las nuevas funciones empíricas.
V3: Del 16/08/25. Desafortunadamente, tuve que deshacerme de las nuevas funciones empíricas. Opté por un nuevo método: dejar todo el proceso de imputación a una sola función de utilidad, y dejar las funciones empíricas como básicas. Así se entiende mejor el código (aunque la función de imputación da miedo). Ojalá se me hubiese ocurrido antes... Volví a ejecutar las celdas con este cambio en mente.
V4: Del 17/08/25 y 18/08/25. Sustituí la antigua heurística para muestras con tiempo de censura mayor que el mayor tiempo de evento - implementé la regla 1.33*tiempo. También implementé código para crear visualizaciones, lo cual abulta muchísimo, y tuve que crear muchas celdas... Al día siguiente corregí errores en la parte de visualización, y dejé la ejecución en el portátil.
V5: Del 21/08/25 y 22/08/25. Encontré en el portátil unos parámetros de orden 3 espectaculares, e hice con ellos inferencia sobre una muestra grande sin censura (5000 individuos). Desafortunadamente, el optimizador actual no funciona para esta muestra...
V6: Del 24/08/25. Enorme cambio, el optimizador ahora es más inteligente. Solo calcula descensos de gradiente para las top 20 mejores inicializaciones, e inicializa sobre miles de parámetros, en vez de 20. También moví el cálculo de los datos empíricos a la función de optimización, fuera de la objetivo. ¡Ahora da aproximaciones mucho mejores!
V7 y V8: Del 25/08/25 hasta el 29/08/25. Repetí los experimentos para las muestras sin censura.
V9: De septiembre. Hice las pruebas de las muestras con censura.
V10: De septiembre. Arreglé un error terrible que hacía que a veces apareciesen parámetros inválidos, había que poner la condición keep_feasible=True en la definición de la clase Bounds.